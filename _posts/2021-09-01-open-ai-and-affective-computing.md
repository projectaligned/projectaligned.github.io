---
title: 'Open AI and Affective Computing'
date: 2020-09-01
permalink: /posts/2020/09/open-ai-and-affective-computing/
tags:
  - affective-computing
  - open-ai
---

_This post is excerpted from my response to the Open AI Scholars application asking why I want to join the program._

I have read the Open AI Charter, the blog posts and papers published by Open AI, and the previous Open AI Scholars’ work. I believe that participating in the Scholars program will serve as an excellent stepping stone towards helping me achieve my long-term goal of effectively and ethically applying deep learning towards meaningful problems in affective computing. Specifically, the publications and demos show that quality research happens at Open AI. The Charter and the careful approach to distributing GPT-2 and GPT-3 indicate that Open AI takes bias and misuse seriously. Finally, I am excited to join a diverse community of scholars. The scholars have some experiences that I share and others I can learn from and grow to understand.

In particular, I am excited by the achievements that past scholars have made during the program. For example, the work that Alethea Power and Fatma Tarlaci have done on interpreting GPT-2 and applying it to Q&A stands out to me as high quality. Likewise, the work on GANs that Janet Brown and Holly Grimm have done is both fun and deep. With these projects as a reference point, I look forward to seeing what I will accomplish during the program.

A recurring theme I've noticed in the past scholars’ blogs is an appreciation for their mentors’ support. Similarly, I am looking forward to collaborating directly with the authors of the papers and blogs that I read. For example, I was pleasantly surprised to see that Natasha Jacques, author of several Affective Computing papers I've read from the Picard Group, has been a mentor to Open AI scholars.

As I noted in my response to the deep learning prompt above, my specific goal for this 6-month long program is to build the technical foundation necessary for a fruitful collaboration with leading researchers in Affective Computing. I have already started working towards this goal over the past several months by reading papers in Affective Computing and presenting on the methods used in the Sisu Machine Learning Journal Club. Sisu has been a fantastic place to develop my skill set as an engineer building a scalable and stable machine learning product. I believe that I can make faster progress towards my long-term goals by focusing entirely on a specific set of deep learning skills for six months.

Concretely speaking, this means that I want to build familiarity with multi-modal learning, multi-task learning, and transformers. The main goal here is to understand and implement several papers from the Picard Group. In particular, I want to extend “Improving Students’ Daily Life Stress Forecasting using LSTM Neural Networks” to use Transformers instead of LSTMs. I also want to understand how to personalize a deep learning model using multi-task learning. Finally, I want to gain experience fusing multiple data sources (for example, smartphone data and wearable data) to improve model accuracy using multi-modal learning.

Given that Affective AI can be easily used to manipulate people rather than benefit them, I must approach the field with care and humility. Based on the Open AI Charter and organizational track record, I believe that Open AI offers the right environment. This consideration makes Open AI more compelling than other organizations that have not stated their values so explicitly. Furthermore, since Open AI emphasizes cooperation, I am excited by the opportunity to collaborate with other research organizations that may have interesting Affective Computing datasets.

Finally, I believe that I can make a meaningful contribution to the Open AI Charter through my focus on understanding emotions. To make Artificial General Intelligence broadly beneficial to humanity, the AGI must take actions that reflect human values. It is not enough to infer these principles from a small group of developers’ assumptions or revealed preferences. No, the AGI must include an assessment of human emotions for as many people as possible.
